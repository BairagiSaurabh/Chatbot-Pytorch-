{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc388a15",
   "metadata": {},
   "source": [
    "# Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf32217e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\PANCHAYAT  SAMITI\n",
      "[nltk_data]     01\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from re import A\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd48968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "with open('intents.json', 'r') as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a01b09",
   "metadata": {},
   "source": [
    "# Data Preprocessing: (Defining Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2fe5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())\n",
    "\n",
    "def bag_of_words(tokenized_sentence, all_words):\n",
    "\n",
    "    tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
    "\n",
    "    bag = np.zeros(len(all_words), dtype=np.float32)\n",
    "    for idx, w in enumerate(all_words):\n",
    "        if w in tokenized_sentence:\n",
    "            bag[idx] = 1.0\n",
    "\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac45dfc",
   "metadata": {},
   "source": [
    "# Neural Network: (Creating the Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d3428c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the neural network that we'll use to train the data\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d2273",
   "metadata": {},
   "source": [
    "# Load model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2036875",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "model_state = data[\"model_state\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc74c94c",
   "metadata": {},
   "source": [
    "# Let's chat ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6160791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat! (type 'quit' to exit)\n",
      "You: hi\n",
      "Sam: Hey :-)\n",
      "You: what do you sell\n",
      "Sam: We sell coffee and tea\n",
      "You: what is the delivery time\n",
      "Sam: Hello, thanks for visiting\n",
      "You: when can I get the delivery\n",
      "Sam: Delivery takes 2-4 days\n",
      "You: okay thanks\n",
      "Sam: My pleasure\n",
      "You: do you take cash for payment\n",
      "Sam: We accept most major credit cards, and Paypal\n",
      "You: Thanks again\n",
      "Sam: Happy to help!\n",
      "You: okay goodbye\n",
      "Sam: Bye! Come back again soon.\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(model_state) # loading the learnt parametres\n",
    "model.eval()\n",
    "\n",
    "bot_name = \"Sam\"\n",
    "print(\"Let's chat! (type 'quit' to exit)\")\n",
    "while True:\n",
    "    sentence = input(\"You: \")\n",
    "    if sentence == \"quit\":\n",
    "        break\n",
    "\n",
    "    sentence = tokenize(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0]) # converting to just one row since we have a single sentence\n",
    "    X = torch.from_numpy(X).to(device) # converting to torch tensor\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    # during training, crossentropy loss automatically applies softmax.\n",
    "    # to get maximum probability as the prediction; we manually apply the softmax function below\n",
    "    \n",
    "    \n",
    "    probs = torch.softmax(output, dim=1) \n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "    else:\n",
    "        print(f\"{bot_name}: I do not understand...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5773c71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
