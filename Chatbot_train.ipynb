{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8288a822",
   "metadata": {},
   "source": [
    "# Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf32217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import A\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd48968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "with open('intents.json', 'r') as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834aec6b",
   "metadata": {},
   "source": [
    "# Data Preprocessing: (Defining Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2fe5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())\n",
    "\n",
    "def bag_of_words(tokenized_sentence, all_words):\n",
    "\n",
    "    tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
    "\n",
    "    bag = np.zeros(len(all_words), dtype=np.float32)\n",
    "    for idx, w in enumerate(all_words):\n",
    "        if w in tokenized_sentence:\n",
    "            bag[idx] = 1.0\n",
    "\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc9a31",
   "metadata": {},
   "source": [
    "# Neural Network: (Creating the Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3428c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the neural network that we'll use to train the data\n",
    "# We define the layers in the first function\n",
    "# In the second function, we are passing the inputs through the NN. \n",
    "# Every output is passed through the ReLU function before going to the next layer \n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4005ca2",
   "metadata": {},
   "source": [
    "# Applying Data Preprocessing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "970ae732",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        w = tokenize(pattern)  # tokenizing all words in the patterns (potential questions)\n",
    "        all_words.extend(w)  # we use extend instead of append because pattern is already an array and we don't want to put an array in an array\n",
    "        xy.append((w, tag))\n",
    "    \n",
    "ignore_words = ['?', '!', '.', ',']\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words] #stemming all the words and ignoring punctuation \n",
    "all_words = sorted(set(all_words))  # using set() removes duplicate elements\n",
    "tags = sorted(set(tags))  #adds unique labels (not necessary but do it in to be safe) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca30450",
   "metadata": {},
   "source": [
    "# Creating Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01d6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for (pattern_sentence, tag) in xy:\n",
    "    bag = bag_of_words(pattern_sentence, all_words) \n",
    "    X_train.append(bag)\n",
    "\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label) #cross entropy loss\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afabdafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step is not necessary, but it makes any potential debugging a lot easier.\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "    #dataset[idx]\n",
    "    def __getitem__(self,index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8500252",
   "metadata": {},
   "source": [
    "# Training Process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db9a7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "\n",
    "batch_size = 8\n",
    "hidden_size = 8\n",
    "output_size = len(tags)\n",
    "input_size = len(X_train[0])\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "035c76f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the dataset and model\n",
    "\n",
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset = dataset, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "    \n",
    "#Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60338c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.9485\n",
      "Epoch [200/1000], Loss: 0.1328\n",
      "Epoch [300/1000], Loss: 0.0527\n",
      "Epoch [400/1000], Loss: 0.0090\n",
      "Epoch [500/1000], Loss: 0.0080\n",
      "Epoch [600/1000], Loss: 0.0025\n",
      "Epoch [700/1000], Loss: 0.0047\n",
      "Epoch [800/1000], Loss: 0.0009\n",
      "Epoch [900/1000], Loss: 0.0007\n",
      "Epoch [1000/1000], Loss: 0.0008\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for (words, labels) in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(words)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #backward and optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch +1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "#print(f'final loss, loss={loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d7ccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss, loss=0.0008\n"
     ]
    }
   ],
   "source": [
    "print(f'final loss, loss={loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed41af",
   "metadata": {},
   "source": [
    "# Save Model and Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "773a931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model_state\" : model.state_dict(),\n",
    "    \"input_size\" : input_size,\n",
    "    \"output_size\" : output_size,\n",
    "    \"hidden_size\" : hidden_size,\n",
    "    \"all_words\" : all_words,\n",
    "    \"tags\" : tags\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(data,FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa9190a",
   "metadata": {},
   "source": [
    "# Load model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2036875",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "model_state = data[\"model_state\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4751a14",
   "metadata": {},
   "source": [
    "# Let's chat ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6160791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat! (type 'quit' to exit)\n",
      "You: hi\n",
      "Sam: Hi there, what can I do for you?\n",
      "You: one joke please\n",
      "Sam: I do not understand...\n",
      "You: do you know some joke\n",
      "Sam: Why did the hipster burn his mouth? He drank the coffee before it was cool.\n",
      "You: hahaha\n",
      "Sam: I do not understand...\n",
      "You: okay bye then\n",
      "Sam: Bye! Come back again soon.\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(model_state) # loading the learnt parametres\n",
    "model.eval()\n",
    "\n",
    "bot_name = \"Sam\"\n",
    "print(\"Let's chat! (type 'quit' to exit)\")\n",
    "while True:\n",
    "    sentence = input(\"You: \")\n",
    "    if sentence == \"quit\":\n",
    "        break\n",
    "\n",
    "    sentence = tokenize(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0]) # converting to just one row since we have a single sentence\n",
    "    X = torch.from_numpy(X).to(device) # converting to torch tensor\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    # during training, crossentropy loss automatically applies softmax.\n",
    "    # to get maximum probability as the prediction; we manually apply the softmax function below\n",
    "    \n",
    "    \n",
    "    probs = torch.softmax(output, dim=1) \n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "    else:\n",
    "        print(f\"{bot_name}: I do not understand...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01290c72",
   "metadata": {},
   "source": [
    "# Resources:\n",
    "\n",
    "https://studentsxstudents.com/creating-a-chatbot-with-pytorch-495622d77481\n",
    "\n",
    "\n",
    "https://github.com/SurjaHead/Chatbot-with-PyTorch\n",
    "\n",
    "\n",
    "https://www.python-engineer.com/posts/chatbot-pytorch/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5773c71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
